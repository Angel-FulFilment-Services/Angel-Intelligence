# Database Configuration
AI_DB_HOST=localhost
AI_DB_PORT=3306
AI_DB_DATABASE=ai_calls
AI_DB_USERNAME=root
AI_DB_PASSWORD=

# R2 Storage Configuration
R2_ENDPOINT=https://your-account-id.r2.cloudflarestorage.com
R2_ACCESS_KEY_ID=your-r2-access-key
R2_SECRET_ACCESS_KEY=your-r2-secret-key
R2_BUCKET=call-recordings

# Local Development (set to a folder path to use local files instead of R2)
# Leave empty for production, set to a local path for development
# Example: LOCAL_STORAGE_PATH=C:\path\to\local\recordings
LOCAL_STORAGE_PATH=

# Worker Configuration
POLL_INTERVAL=30  # Seconds between checking for new recordings

# Transcription Segmentation
# Options: "word" for word-level timestamps, "sentence" for sentence-level timestamps
TRANSCRIPT_SEGMENTATION=word

# GPU Configuration
CUDA_VISIBLE_DEVICES=0  # Set to -1 for CPU only

# PII Redaction Configuration
ENABLE_PII_REDACTION=true

# LLM Configuration for Call Analysis
# Set to a HuggingFace model name or local path, or leave empty for basic analysis
# Example: LLM_MODEL_PATH=Qwen/Qwen2.5-3B-Instruct
# Supported models: Qwen/Qwen2.5-3B-Instruct, TinyLlama/TinyLlama-1.1B-Chat-v1.0, meta-llama/Llama-3.2-3B-Instruct
# The model will be auto-downloaded from HuggingFace on first use
LLM_MODEL_PATH=
