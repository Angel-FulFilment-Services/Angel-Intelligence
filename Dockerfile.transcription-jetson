# ==============================================================================
# Angel Intelligence - Transcription Pod Dockerfile (Jetson ARM64 / Thor)
# ==============================================================================
# For L4T R38 / JetPack 7 with CUDA 13.0
# Uses pip wheels from pypi.jetson-ai-lab.io/sbsa/cu130
#
# Build: docker build -f Dockerfile.transcription-jetson -t angel-intelligence:transcription-arm64 .
# Run:   docker run --runtime nvidia -p 8001:8001 angel-intelligence:transcription-arm64

# NVIDIA CUDA 13.0 devel image with cuDNN for ARM64 (Thor/Grace Hopper)
# Must match CUDA version of the torch wheels from pypi.jetson-ai-lab.io/sbsa/cu130
FROM nvidia/cuda:13.0.1-cudnn-devel-ubuntu24.04

LABEL org.opencontainers.image.title="Angel Intelligence Transcription (Thor/Jetson)"
LABEL org.opencontainers.image.description="Shared WhisperX transcription service for ARM64 CUDA 13.0"

# Prevent interactive prompts during package installation
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV ANGEL_ENV=production

WORKDIR /workspace

# Add NVIDIA HPC SDK repo for NVPL (required by SBSA PyTorch wheels)
RUN apt-get update && apt-get install -y --no-install-recommends \
        gnupg2 \
        ca-certificates \
        curl \
    && curl -fsSL https://developer.download.nvidia.com/hpc-sdk/ubuntu/DEB-GPG-KEY-NVIDIA-HPC-SDK | gpg --dearmor -o /usr/share/keyrings/nvidia-hpcsdk-keyring.gpg \
    && echo "deb [signed-by=/usr/share/keyrings/nvidia-hpcsdk-keyring.gpg] https://developer.download.nvidia.com/hpc-sdk/ubuntu/aarch64 /" > /etc/apt/sources.list.d/nvidia-hpcsdk.list \
    && apt-get update

# Install system dependencies including Python 3.12, ffmpeg, build tools, and NVPL
RUN apt-get install -y --no-install-recommends \
        python3.12 \
        python3.12-dev \
        python3.12-venv \
        python3-pip \
        ffmpeg \
        sox libsox-fmt-all \
        git \
        curl \
        build-essential \
        nvpl \
    && rm -rf /var/lib/apt/lists/* \
    && ln -sf /usr/bin/python3.12 /usr/bin/python3 \
    && ln -sf /usr/bin/python3.12 /usr/bin/python

# Set library path to find NVPL
ENV LD_LIBRARY_PATH="/opt/nvidia/nvpl/lib:${LD_LIBRARY_PATH}"

# Create and activate virtual environment
RUN python3 -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Upgrade pip
RUN pip install --no-cache-dir --upgrade pip setuptools wheel

# Install PyTorch with CUDA 13.0 from Jetson AI Lab pip server (for Thor/SBSA)
# IMPORTANT: Use only the Jetson index for torch to avoid getting CPU-only wheels from PyPI
RUN pip install --no-cache-dir \
    torch==2.9.1 \
    torchaudio==2.9.1 \
    --index-url https://pypi.jetson-ai-lab.io/sbsa/cu130/+simple/

# Verify CUDA torch was installed (not CPU version)
RUN python3 -c "import torch; assert 'cpu' not in torch.__version__, 'CPU-only torch installed!'; print('torch', torch.__version__, 'OK')"

# Copy requirements
COPY requirements/base.txt requirements/
COPY requirements/transcription.txt requirements/

# Install WhisperX and dependencies
RUN pip install --no-cache-dir faster-whisper==1.1.0
RUN pip install --no-cache-dir git+https://github.com/m-bain/whisperx.git --no-deps

# Install pyannote for speaker diarization
# Use git master to get torchaudio 2.9.x compatibility fixes
RUN pip install --no-cache-dir git+https://github.com/pyannote/pyannote-audio.git

# Install minimal WhisperX deps and other transcription dependencies
RUN pip install --no-cache-dir pandas nltk more-itertools
RUN pip install --no-cache-dir -r requirements/transcription.txt 2>/dev/null || true

# Copy only necessary code
COPY src/api/app.py src/api/
COPY src/api/auth.py src/api/
COPY src/api/routes.py src/api/
COPY src/api/routes_live.py src/api/
COPY src/api/__init__.py src/api/
COPY src/config/ src/config/
COPY src/database/ src/database/
COPY src/services/ src/services/
COPY src/__init__.py src/

EXPOSE 8001

CMD ["python", "-m", "uvicorn", "src.api:app", "--host", "0.0.0.0", "--port", "8001"]
