# ==============================================================================
# Angel Intelligence - Transcription Pod Dockerfile (Jetson ARM64 / Thor)
# ==============================================================================
# Uses NGC vLLM base which has working CUDA-enabled PyTorch on Thor
#
# Build: docker build -f Dockerfile.transcription-jetson -t angel-intelligence:transcription-arm64 .
# Run:   docker run --runtime nvidia -p 8001:8001 angel-intelligence:transcription-arm64

# Use NGC vLLM - same base as working vllm-arm64 image (has CUDA PyTorch)
FROM nvcr.io/nvidia/vllm:26.01-py3

LABEL org.opencontainers.image.title="Angel Intelligence Transcription (Thor/Jetson)"
LABEL org.opencontainers.image.description="Shared WhisperX transcription service for ARM64"

# Prevent interactive prompts during package installation
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV ANGEL_ENV=production

WORKDIR /workspace

# Install additional system dependencies (ffmpeg for whisperx audio loading)
RUN apt-get update && apt-get install -y --no-install-recommends \
        ffmpeg \
        sox libsox-fmt-all \
    && rm -rf /var/lib/apt/lists/*

# Install torchaudio from Jetson pip server (matches base PyTorch)
RUN pip install --no-cache-dir torchaudio \
    --index-url https://pypi.jetson-ai-lab.io/jp6/cu128/+simple/ \
    --extra-index-url https://pypi.org/simple

# Verify PyTorch has CUDA
RUN python3 -c "import torch; print('PyTorch:', torch.__version__, 'CUDA:', torch.cuda.is_available())"

# Copy requirements
COPY requirements/base.txt requirements/
COPY requirements/transcription.txt requirements/

# Install WhisperX and dependencies
RUN pip install --no-cache-dir faster-whisper
RUN pip install --no-cache-dir git+https://github.com/m-bain/whisperx.git --no-deps

# Install pyannote for speaker diarization
# Check torchaudio version and install compatible pyannote
RUN pip install --no-cache-dir pyannote.audio || \
    pip install --no-cache-dir git+https://github.com/pyannote/pyannote-audio.git

# Install minimal WhisperX deps and other transcription dependencies
RUN pip install --no-cache-dir pandas nltk more-itertools
RUN pip install --no-cache-dir -r requirements/transcription.txt 2>/dev/null || true

# Copy only necessary code
COPY src/api/app.py src/api/
COPY src/api/auth.py src/api/
COPY src/api/routes.py src/api/
COPY src/api/routes_live.py src/api/
COPY src/api/__init__.py src/api/
COPY src/config/ src/config/
COPY src/database/ src/database/
COPY src/services/ src/services/
COPY src/__init__.py src/

EXPOSE 8001

# Run with multiple workers for concurrent request handling
# Thread pool handles GPU work, workers handle I/O parallelism
CMD ["python3", "-m", "uvicorn", "src.api:app", "--host", "0.0.0.0", "--port", "8001", "--workers", "2"]
