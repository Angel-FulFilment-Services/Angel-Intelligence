apiVersion: apps/v1
kind: Deployment
metadata:
  name: angel-intelligence-batch-worker
  namespace: default
  labels:
    app: angel-intelligence
    component: batch-worker
spec:
  # Reduced replicas for Jetson resource constraints
  replicas: 0
  selector:
    matchLabels:
      app: angel-intelligence
      component: batch-worker
  template:
    metadata:
      labels:
        app: angel-intelligence
        component: batch-worker
    spec:
      # Use NVIDIA runtime for GPU access
      runtimeClassName: nvidia
      
      hostAliases:
        - ip: "192.168.5.13"
          hostnames:
            - "afs-db02.angelfs.co.uk"

      # Distribute workers across different nodes
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - angel-intelligence
              topologyKey: kubernetes.io/hostname

      containers:
      - name: worker
        image: 192.168.9.50:30500/angel-intelligence:latest-arm64
        imagePullPolicy: IfNotPresent

        # LD_PRELOAD fixes ARM64 OpenMP TLS issue
        command: ["/bin/sh", "-c", "export LD_PRELOAD=/usr/lib/aarch64-linux-gnu/libgomp.so.1; python -m src.worker.worker"]

        env:
        # Fix ARM64 OpenMP TLS issue
        - name: LD_PRELOAD
          value: "/usr/lib/aarch64-linux-gnu/libgomp.so.1"
        # Use local models only - no HuggingFace downloads
        - name: HF_HUB_OFFLINE
          value: "1"
        - name: TRANSFORMERS_OFFLINE
          value: "1"
        # Environment
        - name: ANGEL_ENV
          value: "production"
        - name: WORKER_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        # Worker mode - batch for call processing
        - name: WORKER_MODE
          value: "batch"

        # Database configuration
        - name: AI_DB_HOST
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: db-host
        - name: AI_DB_PORT
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: db-port
        - name: AI_DB_DATABASE
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: db-database
        - name: AI_DB_USERNAME
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: db-username
        - name: AI_DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: db-password

        # R2 Storage configuration
        - name: R2_ENDPOINT
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: r2-endpoint
        - name: R2_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: r2-access-key-id
        - name: R2_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: r2-secret-access-key
        - name: R2_BUCKET
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: r2-bucket

        # Processing settings from ConfigMap
        - name: POLL_INTERVAL
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: poll-interval
        - name: ANALYSIS_MODE
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: analysis-mode
        - name: WHISPER_MODEL
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: whisper-model
        - name: WHISPER_MODEL_PATH
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: whisper-model-path
        - name: ANALYSIS_MODEL
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: analysis-model
        - name: ANALYSIS_MODEL_PATH
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: analysis-model-path
        - name: ANALYSIS_MODEL_QUANTIZATION
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: analysis-model-quantization
        - name: TRANSCRIPT_SEGMENTATION
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: transcript-segmentation
        - name: ENABLE_PII_REDACTION
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: enable-pii-redaction

        # PBX Sources
        - name: PBX_LIVE_URL
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: pbx-live-url
        - name: PBX_ARCHIVE_URL
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: pbx-archive-url

        # GPU
        - name: CUDA_VISIBLE_DEVICES
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: cuda-visible-devices

        # Chat model (for any interactive features in batch worker)
        - name: CHAT_MODEL
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: chat-model
        - name: CHAT_MODEL_PATH
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: chat-model-path
        - name: CHAT_MODEL_QUANTIZATION
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: chat-model-quantization
        - name: PRELOAD_CHAT_MODEL
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: preload-chat-model

        resources:
          limits:
            nvidia.com/gpu: 1
            memory: "6Gi"
          requests:
            memory: "4Gi"
            cpu: "1"

        volumeMounts:
        - name: models
          mountPath: /models
          readOnly: true
        - name: model-cache
          mountPath: /root/.cache

      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: angel-intelligence-models
      - name: model-cache
        hostPath:
          path: /mnt/model-cache
          type: DirectoryOrCreate

      # Only schedule on nodes with GPU
      nodeSelector:
        nvidia.com/gpu: "true"

      restartPolicy: Always

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: angel-intelligence-api
  namespace: default
  labels:
    app: angel-intelligence
    component: api
spec:
  replicas: 1
  selector:
    matchLabels:
      app: angel-intelligence
      component: api
  template:
    metadata:
      labels:
        app: angel-intelligence
        component: api
    spec:
      hostAliases:
        - ip: "192.168.5.13"
          hostnames:
            - "afs-db02.angelfs.co.uk"

      # Allow scheduling on master/control-plane nodes
      tolerations:
      - key: "node-role.kubernetes.io/control-plane"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "node-role.kubernetes.io/master"
        operator: "Exists"
        effect: "NoSchedule"

      # Prefer scheduling on master node to free up GPU node for AI workloads
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/hostname
                operator: In
                values:
                - afs-kube01

      containers:
      - name: api
        image: 192.168.9.50:30500/angel-intelligence:latest-amd64
        imagePullPolicy: IfNotPresent

        command: ["python3", "-m", "uvicorn", "src.api.app:app", "--host", "0.0.0.0", "--port", "8000"]

        ports:
        - containerPort: 8000
          name: http

        env:
        - name: ANGEL_ENV
          value: "production"
        # Worker mode: api (proxies AI requests to interactive workers)
        - name: WORKER_MODE
          value: "api"
        # Interactive service URL for AI request proxying
        # Points to the K8s ClusterIP service which load-balances across interactive pods
        - name: INTERACTIVE_SERVICE_URL
          value: "http://angel-intelligence-interactive:8000"
        # Don't preload models - API pod proxies to interactive workers
        - name: PRELOAD_CHAT_MODEL
          value: "false"
        - name: API_AUTH_TOKEN
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: api-auth-token
        - name: AI_DB_HOST
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: db-host
        - name: AI_DB_PORT
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: db-port
        - name: AI_DB_DATABASE
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: db-database
        - name: AI_DB_USERNAME
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: db-username
        - name: AI_DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: db-password

        # All model configs (for consistency, even if API proxies)
        - name: WHISPER_MODEL
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: whisper-model
        - name: WHISPER_MODEL_PATH
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: whisper-model-path
        - name: ANALYSIS_MODEL
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: analysis-model
        - name: ANALYSIS_MODEL_PATH
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: analysis-model-path
        - name: ANALYSIS_MODEL_QUANTIZATION
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: analysis-model-quantization
        - name: CHAT_MODEL
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: chat-model
        - name: CHAT_MODEL_PATH
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: chat-model-path
        - name: CHAT_MODEL_QUANTIZATION
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: chat-model-quantization
        - name: CUDA_VISIBLE_DEVICES
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: cuda-visible-devices

        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1"

        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 30

        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 10

      restartPolicy: Always

---
# =============================================================================
# Interactive Worker Deployment
# Handles real-time AI requests: chat, summaries, future AI features
# Scale this based on interactive request volume
# =============================================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: angel-intelligence-interactive
  namespace: default
  labels:
    app: angel-intelligence
    component: interactive
spec:
  # Start with 1 interactive node, scale as needed
  replicas: 1
  selector:
    matchLabels:
      app: angel-intelligence
      component: interactive
  template:
    metadata:
      labels:
        app: angel-intelligence
        component: interactive
    spec:
      # Use NVIDIA runtime for GPU access
      runtimeClassName: nvidia
      
      hostAliases:
        - ip: "192.168.5.13"
          hostnames:
            - "afs-db02.angelfs.co.uk"

      containers:
      - name: interactive
        image: 192.168.9.50:30500/angel-intelligence:latest-arm64
        imagePullPolicy: IfNotPresent

        # Run the API server which handles interactive requests
        # LD_PRELOAD fixes ARM64 OpenMP TLS issue
        command: ["/bin/sh", "-c", "export LD_PRELOAD=/usr/lib/aarch64-linux-gnu/libgomp.so.1; python3.9 -m uvicorn src.api.app:app --host 0.0.0.0 --port 8000"]

        env:
        # Fix ARM64 OpenMP TLS issue
        - name: LD_PRELOAD
          value: "/usr/lib/aarch64-linux-gnu/libgomp.so.1"
        # Use local models only - no HuggingFace downloads
        - name: HF_HUB_OFFLINE
          value: "1"
        - name: TRANSFORMERS_OFFLINE
          value: "1"
        - name: ANGEL_ENV
          value: "production"
        - name: WORKER_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: WORKER_MODE
          value: "interactive"

        # Database
        - name: AI_DB_HOST
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: db-host
        - name: AI_DB_PORT
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: db-port
        - name: AI_DB_DATABASE
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: db-database
        - name: AI_DB_USERNAME
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: db-username
        - name: AI_DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: angel-intelligence-secrets
              key: db-password

        # Chat model for interactive requests
        - name: CHAT_MODEL
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: chat-model
        - name: CHAT_MODEL_PATH
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: chat-model-path
        - name: CHAT_MODEL_QUANTIZATION
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: chat-model-quantization
        # Disable preloading - load on first request instead
        - name: PRELOAD_CHAT_MODEL
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: preload-chat-model

        # Whisper model
        - name: WHISPER_MODEL
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: whisper-model
        - name: WHISPER_MODEL_PATH
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: whisper-model-path

        # Analysis model
        - name: ANALYSIS_MODEL
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: analysis-model
        - name: ANALYSIS_MODEL_PATH
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: analysis-model-path
        - name: ANALYSIS_MODEL_QUANTIZATION
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: analysis-model-quantization

        # GPU
        - name: CUDA_VISIBLE_DEVICES
          valueFrom:
            configMapKeyRef:
              name: angel-intelligence-config
              key: cuda-visible-devices

        ports:
        - containerPort: 8000
          name: http

        resources:
          limits:
            nvidia.com/gpu: 1
            memory: "6Gi"
          requests:
            memory: "4Gi"
            cpu: "1"

        volumeMounts:
        - name: models
          mountPath: /models
          readOnly: true
        - name: model-cache
          mountPath: /root/.cache

        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 30

        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10

      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: angel-intelligence-models
      - name: model-cache
        hostPath:
          path: /mnt/model-cache
          type: DirectoryOrCreate

      # Schedule on GPU nodes
      nodeSelector:
        nvidia.com/gpu: "true"

      restartPolicy: Always

---
apiVersion: v1
kind: Service
metadata:
  name: angel-intelligence-interactive
  namespace: default
  labels:
    app: angel-intelligence
spec:
  # ClusterIP for internal load-balancing across interactive workers
  # API pods proxy to this service for AI requests
  type: ClusterIP
  ports:
  - port: 8000
    targetPort: 8000
    protocol: TCP
    name: http
  selector:
    app: angel-intelligence
    component: interactive

---
apiVersion: v1
kind: Service
metadata:
  name: angel-intelligence-api
  namespace: default
  labels:
    app: angel-intelligence
spec:
  type: NodePort
  ports:
  - port: 80
    targetPort: 8000
    nodePort: 30800
    protocol: TCP
    name: http
  selector:
    app: angel-intelligence
    component: api
