# ==============================================================================
# Angel Intelligence - API Pod Requirements
# ==============================================================================
# Lightweight API server - no ML models, just HTTP routing
# Image size: ~200MB (minimal)
#
# Build: docker build -f Dockerfile.api -t angel-intelligence:api .
# Run:   uvicorn src.api:app --host 0.0.0.0 --port 8000

# Include base dependencies
-r base.txt

# ------------------------------------------------------------------------------
# Web Framework
# ------------------------------------------------------------------------------
fastapi==0.115.0
uvicorn[standard]==0.32.0
python-multipart==0.0.12

# ------------------------------------------------------------------------------
# HTTP Client (for proxying to services)
# ------------------------------------------------------------------------------
httpx==0.27.2

# ------------------------------------------------------------------------------
# Database
# ------------------------------------------------------------------------------
mysql-connector-python==9.1.0

# ------------------------------------------------------------------------------
# Cloud Storage (R2/S3)
# ------------------------------------------------------------------------------
boto3==1.35.74

# ------------------------------------------------------------------------------
# JSON Repair (for handling malformed LLM responses in services)
# ------------------------------------------------------------------------------
json-repair==0.30.3

# ------------------------------------------------------------------------------
# Optional: Redis for job queuing (if using RQ)
# ------------------------------------------------------------------------------
# redis==5.0.0
# rq==1.16.0
